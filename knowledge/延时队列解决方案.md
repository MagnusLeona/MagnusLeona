#### 定时任务删除超时的订单

> 背景：订单支付系统功能，如果客户没有支付成功或者取消支付，就会将订单挂起。超过一定时间后，将这个订单取消。所以需要有个定时的任务去清理这些超时的订单。



##### 方案一：定时任务+Redis实现

> 设计思路：Redis中有`zset`数据结构，可以针对元素排序。可以使用时间戳作为每个元素的`score`，然后有个服务定时的去扫描这个set去获取可以执行的数据。同时，要有一个队列去专门维护所有任务对应的具体信息，在redis中可以使用`hashmap`表示。还需要一个当前已经失效的任务队列，用于维护已经到时间的需要执行的所有任务。所以，就需要有一个定时任务去定期扫描`zset`中到了执行时间的任务，将任务搬到`list`执行队列中，并需要有个服务去不停的执行list中放入的所有任务。

- 设计目标：
  - 高可用：可以支持分布式集群部署。
  - 消息可靠：每个任务只会被执行一次，不会被重复执行。
  - 持久化：支持持久化机制。
  - 强一致性：消息不会丢失，需要ack应答机制去保证。

- 具体实现：

  - 定义一个任务`DelayedJob`实体：

    ```java
    @Data
    @AllArgsConstructor
    @NoArgsConstructor
    public class DelayedJob {
        private String jobId;    // jobId Job的唯一标识
        private String topicId;       // topicId
        private Long delayTime;
        private String jobBody;
        private int retry;
    }
    ```

    主要用于表示每一个单体任务的相关信息。

  - 一个可以定时扫描`zset`集合中超时的任务，并转移到`list`执行队列中。<font color="red">如果遇到微服务多机部署，需要保证同时只能有一个任务在扫描zset，否则会出现消息重复搬运的问题。所以，此时就需要设置一个分布式锁，定时任务会优先检查能否获取锁，获取了锁才能做扫描和转移操作。</font>涉及的redis操作包括，`set key nx timeout`,`zrangebyscore key start end`,`rpush key values `,`zrem key member`。

    ```java
    @Component
    public class TimeoutJobCollectorExecutor {
    
        @Autowired
        RedisService redisService;
    
        @PostConstruct
        public void tryToCollectTimeoutJobs() {
            // 搬运已失效的任务到执行队列中
            // 需要先获取分布式锁
            if (redisService.tryLock()) {
                try {
                    long instantTime = Instant.now().toEpochMilli();
                    Optional<Set<String>> timeoutJobs = 
                        redisService.zrangeByScore("DelayedJobsSet", 0, instantTime);
                    // 将任务放到待处理的队列中
                    timeoutJobs.ifPresent(jobs -> {
                        redisService.rpushAll("DelayedJobsList", jobs.toArray(new String[]{}));
                        jobs.forEach(job -> redisService.zremove("DelayedJobsSet", job));
                    });
                } finally {
                    redisService.unLock();
                }
            }
        }
    }
    ```

  - 延时任务消费：多个消费者，从执行队列`list`中每次拿最顶上一个任务编号，然后进行相应的逻辑处理。处理有两种结果，成功了，则从`DelayedJobsPool`中删除这个任务的相关信息，此`DelayedJob`完成处理。失败了，则需要重试几次。重试通过将此任务重新插入`DelayedJobsList`来重复执行。同时，`DelayedJob`实体中会存放当前重试的次数，如果超过一定的次数，直接将此`DelayedJob`持久化到一个异常数据库中，后续做特殊分析用。<font color="red">消费者每次去`list`中获取数据的时候，如果`list`是空的，那么就会做很多无效的循环。所以可以考虑使用`redis`的`blpop`操作，阻塞一段时间，如果阻塞的这段时间一直没有数据，则返回null。这样减少了很多重复的读取。</font>为了加快消费速度，可以使用线程池的方式去执行。<font color="purple">存储`DelayedJob`采用`JSON`的格式，使用`FastJson`处理。</font>

    ```java
    @Component
    @Slf4j
    public class OrderSuspendedCleanExecutor implements DelayJobHandlerExecutor, DisposableBean {
        
        // 监听容器关闭事件
        public volatile boolean destroyed = false;
    
        ThreadPoolExecutor threadPoolExecutor;
        ThreadPoolExecutor handleJobExecutor;
    
        @Autowired
        public RedisService redisService;
    
        @Autowired
        public OrderService orderService;
    
        @PostConstruct
        public void postHandle() {
            threadPoolExecutor = new ThreadPoolExecutor(
                    5,
                    10,
                    1000,
                    TimeUnit.SECONDS,
                    new ArrayBlockingQueue<>(10),
                    Thread::new,
                    new ThreadPoolExecutor.DiscardOldestPolicy());
            handleJobExecutor = new ThreadPoolExecutor(
                    1,
                    1,
                    0,
                    TimeUnit.SECONDS,
                    new ArrayBlockingQueue<>(1),
                    Thread::new,
                    new ThreadPoolExecutor.CallerRunsPolicy());
            handleJobExecutor.submit(this::handleDelayedJob);
        }
    
        @Override
        public void handleDelayedJob() {
            if (log.isDebugEnabled()) {
                log.debug("looping for expired orders");
            }
            for (; ; ) {
                // 执行逻辑
                // 每次从任务队列中获取一条记录
                try {
                    if (destroyed) {
                        break;
                    }
                    String timeoutOrder = redisService.blpop("DelayedJobsList", 2000L);
                    if (timeoutOrder == null) {
                        continue;
                    }
                    if (log.isDebugEnabled()) {
                        log.debug("timeout order {} scanned", timeoutOrder);
                    }
                    String hget = redisService.hget("DelayedJobsPool", timeoutOrder);
                    DelayedJob delayedJob = JSON.parseObject(hget, DelayedJob.class);
                    // 修改数据库中此数据
                    Future<Boolean> submit = threadPoolExecutor.submit(() ->
                            orderService.cancelSuspendedOrder(Long.valueOf(delayedJob.getJobId())));
                    // 成功？删除此Job
                    if (submit.get()) {
                        redisService.hdel("DelayedJobsPool", delayedJob.getJobId());
                    } else {
                        // 异常重试
                        // 判断当前是否超出重试次数 默认是5次
                        if (delayedJob.getRetry() >= 5) {
                            // 将这个订单记录到数据库中
                            redisService.hdel("DelayedJobsPool", delayedJob.getJobId());
                            // 持久化到数据库中，记录异常日志
                        }
                        // 没有超出重试次数，则重新放回job-pool中，并重新放到执行队列中
                        delayedJob.setRetry(delayedJob.getRetry() + 1);
                        redisService.hset("DelayedJobsPool", timeoutOrder, 																							JSON.toJSONString(delayedJob));
                        redisService.rpush("DelayedJobsList", timeoutOrder);
                    }
                } catch (Exception e) {
                    log.info(e.getMessage());
                }
            }
        }
    
        @Override
        public void destroy() {
            this.destroyed = true;
            threadPoolExecutor.shutdown();
            handleJobExecutor.shutdown();
        }
    }
    ```

    上述代码，新建了两个线程池用来执行任务，其中一个线程池是用来执行当前类的`handleDelayedJob`方法。需要注意，这里如果不使用线程池而是直接调用`handleDelayedJob`方法，则spring容器的加载就会一直停留在这里。另外一个线程池用于处理实际的业务逻辑，加快数据处理的速度。<font color="red">需要特别注意的是，因为我们在这里新建了两个线程池，并且线程池中的方法是永久执行的（for(;;)，所以在出发容器关闭事件的时候，这两个线程池中的线程处理并没有受到影响，所以会一直执行。但是，此时redis连接相关的bean都已经被注销了，那么这个时候线程就会大量的报错。所以解决方法就是，加上这个执行器的bean销毁事件监听，在销毁的时候主动关闭线程池。为了解决线程一直在无限循环的问题，加入了volatile变量destroyed来控制正在执行的线程是否需要退出循环。）</font>

  - 添加、删除`DelayedJob`：添加和删除`DelayedJob`的时候需要注意和定时扫描的任务不能产生冲突。

    下面是Controller对应的代码：

    ```java
    @RestController
    public class OrderSuspendController {
    
        @Autowired
        OrderService orderService;
    
        @GetMapping("order/suspend/{id}")
        public MagnusResponse<Object> suspendOrder(@PathVariable Long id) {
            // 模拟新增数据
            orderService.insertOrder(new Order(id, "123", "1"));
            // 模拟挂起订单
            orderService.orderSuspend(id);
            return new MagnusResponse<>(200, null, "success");
        }
    
        @PostMapping("order/suspend/{id}/pay")
        public MagnusResponse<Object> payForSuspendedOrder(@PathVariable Long id) {
            orderService.payForSuspendedOrder(id);
            return new MagnusResponse<>();
        }
    }
    ```

    下面是Service对应的代码：

    ```java
    @Service
    @Slf4j
    public class OrderServiceImpl implements OrderService {
    
        @Resource
        OrderMapper orderMapper;
    
        @Autowired
        RedisService redisService;
    
        /*
        添加延时任务
        */
        @Override
        @Transactional
        public void orderSuspend(Long id) {
            // 业务逻辑处理，修改订单状态---将订单挂起
            orderMapper.updateOrderStatus(id, "0", "1");
            // 然后放到redis任务队列中
            DelayedJob delayedJob = new DelayedJob();
            delayedJob.setJobId(String.valueOf(id));
            delayedJob.setDelayTime(3000L);
            delayedJob.setRetry(5);
            // 存放任务索引id和任务的失效时间（不同的任务可能有不同的失效时间）
            try {
                while (true) {
                    // 自旋去获取锁
                    if (!redisService.tryLock()) {
                        continue;
                    }
                    // 假设需要的延迟事件是1分钟，直接把当前时间+1分钟存到zset中
                    redisService.zadd("DelayedJobsSet", String.valueOf(id), (double) 																		Instant.now().toEpochMilli() + 60 * 1000L);
                    // 存放任务的具体信息（这里其实可以简化，因为我这个业务场景并不复杂）
                    redisService.hset("DelayedJobsPool", delayedJob.getJobId(), 																			JSON.toJSONString(delayedJob));
                    break;
                }
            } finally {
                redisService.unLock();
            }
        }
        
        /*
         删除延时任务
        */
        @Override
        @Transactional
        public boolean cancelSuspendedOrder(Long id) {
            // 先锁行数据
            try {
                Order order = orderMapper.selectOrderByIdForUpdate(id);
                if (order == null || order.getStatus().compareTo("1") >= 0) {
                    // 如果相等
                    orderMapper.updateOrderStatus(id, "1", "-1");
                }
                return true;
            } catch (Exception e) {
                log.error(e.getMessage());
                return false;
            }
        }
        
        /*
         处理延时任务
        */
       	@Override
       	@Transactional
        public boolean payForSuspendedOrder(Long id) {
            // 支付挂起的订单
            // 需要放到事务中去执行
            Order order = orderMapper.selectOrderByIdForUpdate(id);
            // select for update将会锁行数据
            // todo: 是否可以考虑只返回status
            if (order.getStatus().equals(OrderStatusEnum.HANGED.get())) {
                // 如果当前是挂起的状态，则继续执行操作
                orderMapper.updateOrderStatus(id, "1", "2");
                // 需要检测zrem是否是成功操作，如果这个时候数据被转移到list中了，则这一步操作会失败，默认已经失效。
                return redisService.zremove("DelayedJobsSet", String.valueOf(id));
            }
            return false;
        }
    }
    ```

    至此，整个延时队列就设计完成了。但是还有很多需要改进的地方。

> 总结下思路：
>
> ​		首先，延时队列所使用到的容器包括：zset有序集合，用来存放任务ID和时间映射关系；list先进先出，用来存放已经超时，需要进行处理的任务；map，用来存放任务ID和任务具体信息的映射关系。
>
> ​		初始化的时候，先创建一个定时任务，每隔1s扫描一次zset查看是否有过期的任务。如果有，则将任务放到list中。然后创建一个线程，监听list中的数据，不停的从list中获取最顶层的任务并交给线程池去执行。然后就是任务的创建者，在接收到创建任务的请求后，向zset中存放任务ID，向map中存放任务对应的相关数据。然后就是任务的清除。假如需要中途清除掉任务，那么就检查zset中是否有此任务ID，如果有，则删除，如果没有，则表示任务已经被执行了，或者任务已经被放到list中等待执行，此时直接返回无法删除即可。
>
> > 思考：这里是如果保证消息不重复消费的？
> >
> > 生产者端：生产者端会通过zset去重，对于同一个任务ID，只会有一条记录。在消息搬运到待处理列表list中的时候，使用了分布式锁，同时只能有一个线程去做搬运或者增加/删除的操作。所以消息不会重复被搬运到list中。
> >
> > 消费者端：消费者通过redis的lpop操作，每次走list中获取最顶上的一个。因为redis内部是单线程，所以能保证多线程访问的时候不会同时pop出同一条数据，能保证消息仅能被一个消费者获取到。

> 有些问题待思考：
>
> - 如何保证消息不丢失？如果消息被某一个消费者刚获取到，这个时候因为一些异常情况，消费者服务挂了，那么这个消息就消费失败了。这个时候需要怎么办？
>
>   - 是否可以使用ACK机制？怎么样使用？
>
>     等待执行的队列，有一个线程从Queue中取出一条数据，需要放到一个正在执行的任务Map中，map记录当前执行的情况。如果执行成功，则走map中删除这一条记录，表示客户端正确处理。如果超过一定时间不成功，则直接将这条记录重新放回到等待执行的队列。思考：<font color="red">这样是否就能保证绝对安全了？</font>显然不行。考虑这样一种情况：线程queue走等待队列Queue中获取了一个任务，正准备放到正在执行的任务Map记录中的时候挂掉了，这时候map中没有成功记录此任务，而此任务也没有正确被执行，那么就出现了消息丢失的情况。这样又怎么解决呢？是否可以基于Redis的`lua`脚本去保证从等待队列Queue中取任务和将任务放到正在执行的任务Map这两个操作原子化？
>
>   - 另外一种措施就是数据库容错机制：有个定时任务去扫描数据库中挂起的订单，如果此订单id对应的任务Id在redis中找不到，那么说明这是一笔无效订单，直接发起超时处理。
>
> - 如果业务逻辑中允许提前删除待处理的任务（订单被支付了），如果恰好这个时候被搬运任务的线程扫描到任务失效了，转移到了待处理的队列，这个时候如果处理提前删除这笔订单的操作？（前提：<font color="red">任何对zset的直接访问，都需要获得分布式锁。</font>）
>
>   - 如果是在处理待删除的任务的数据库操作前直接加上redis的分布式锁，是否会影响到其他线程访问redis，而造成总处理速度变慢？
>
>     ```java
>     // 伪代码
>     redis加锁
>     修改数据库中的数据
>     删除redis中的记录
>     redis解锁
>     ```
>
>     如果修改数据库中的数据这一步处理很慢，那么必然会严重影响系统的整体性能。如果在并发量不高的情况下，可以这样考虑。
>
>   - 是否可以考虑，只对删除redis中的记录这一步操作加分布式锁，在整个Service方法上加上数据库事务，对所有的Exception进行回滚，如果删除redis失败了（zrem命令在没有成功删除的时候会返回0，成功删除返回1），则回滚数据库的修改记录？ 
>
>     ```java
>     // 伪代码
>     修改数据库中的数据
>     redis加锁
>     删除redis中的记录
>     删除成功？ 结束
>     删除失败？ 回滚
>     ```
>
> - 如果保证高并发下，消费的速度能跟得上生产的速度？
>
>   - 将等待队列水平拆分为多个队列，设置多个消费者对接此等待队列。
>   - 队列中的任务按照任务类型进行拆分。
